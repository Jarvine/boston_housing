<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>sklearn.tree.DecisionTreeRegressor &mdash; Project 1 (Predicting Boston Housing Prices) 2016.02.21 documentation</title>
    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootswatch-3.3.4/readable/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2016.02.21',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.4/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="Project 1 (Predicting Boston Housing Prices) 2016.02.21 documentation" href="../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          Project 1 (Predicting Boston Housing Prices)</a>
        <span class="navbar-text navbar-version pull-left"><b>2016.02.21</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../statistical_analysis.html">Statistical Analysis and Data Exploration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../evaluating_model_performance.html">Evaluating Model Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../analyzing_model_performance.html">Analyzing Model Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_prediction.html">Model Prediction</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">sklearn.tree.DecisionTreeRegressor</a></li>
</ul>
</ul>
</li>
              
            
            
              
                
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/api/sklearn.tree.DecisionTreeRegressor.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="sklearn-tree-decisiontreeregressor">
<h1>sklearn.tree.DecisionTreeRegressor<a class="headerlink" href="#sklearn-tree-decisiontreeregressor" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearn.tree.DecisionTreeRegressor">
<em class="property">class </em><code class="descclassname">sklearn.tree.</code><code class="descname">DecisionTreeRegressor</code><span class="sig-paren">(</span><em>criterion='mse'</em>, <em>splitter='best'</em>, <em>max_depth=None</em>, <em>min_samples_split=2</em>, <em>min_samples_leaf=1</em>, <em>min_weight_fraction_leaf=0.0</em>, <em>max_features=None</em>, <em>random_state=None</em>, <em>max_leaf_nodes=None</em>, <em>presort=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sklearn/tree/tree.html#DecisionTreeRegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>A decision tree regressor.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="docutils">
<dt>criterion <span class="classifier-delimiter">:</span> <span class="classifier">string, optional (default=&#8221;mse&#8221;)</span></dt>
<dd>The function to measure the quality of a split. The only supported
criterion is &#8220;mse&#8221; for the mean squared error, which is equal to
variance reduction as feature selection criterion.</dd>
<dt>splitter <span class="classifier-delimiter">:</span> <span class="classifier">string, optional (default=&#8221;best&#8221;)</span></dt>
<dd>The strategy used to choose the split at each node. Supported
strategies are &#8220;best&#8221; to choose the best split and &#8220;random&#8221; to choose
the best random split.</dd>
<dt>max_features <span class="classifier-delimiter">:</span> <span class="classifier">int, float, string or None, optional (default=None)</span></dt>
<dd><dl class="first docutils">
<dt>The number of features to consider when looking for the best split:</dt>
<dd><ul class="first last simple">
<li>If int, then consider <cite>max_features</cite> features at each split.</li>
<li>If float, then <cite>max_features</cite> is a percentage and
<cite>int(max_features * n_features)</cite> features are considered at each
split.</li>
<li>If &#8220;auto&#8221;, then <cite>max_features=n_features</cite>.</li>
<li>If &#8220;sqrt&#8221;, then <cite>max_features=sqrt(n_features)</cite>.</li>
<li>If &#8220;log2&#8221;, then <cite>max_features=log2(n_features)</cite>.</li>
<li>If None, then <cite>max_features=n_features</cite>.</li>
</ul>
</dd>
</dl>
<p class="last">Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code class="docutils literal"><span class="pre">max_features</span></code> features.</p>
</dd>
<dt>max_depth <span class="classifier-delimiter">:</span> <span class="classifier">int or None, optional (default=None)</span></dt>
<dd>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.
Ignored if <code class="docutils literal"><span class="pre">max_leaf_nodes</span></code> is not None.</dd>
<dt>min_samples_split <span class="classifier-delimiter">:</span> <span class="classifier">int, optional (default=2)</span></dt>
<dd>The minimum number of samples required to split an internal node.</dd>
<dt>min_samples_leaf <span class="classifier-delimiter">:</span> <span class="classifier">int, optional (default=1)</span></dt>
<dd>The minimum number of samples required to be at a leaf node.</dd>
<dt>min_weight_fraction_leaf <span class="classifier-delimiter">:</span> <span class="classifier">float, optional (default=0.)</span></dt>
<dd>The minimum weighted fraction of the input samples required to be at a
leaf node.</dd>
<dt>max_leaf_nodes <span class="classifier-delimiter">:</span> <span class="classifier">int or None, optional (default=None)</span></dt>
<dd>Grow a tree with <code class="docutils literal"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.
If not None then <code class="docutils literal"><span class="pre">max_depth</span></code> will be ignored.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int, RandomState instance or None, optional (default=None)</span></dt>
<dd>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</dd>
<dt>presort <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional (default=False)</span></dt>
<dd>Whether to presort the data to speed up the finding of best splits in
fitting. For the default settings of a decision tree on large
datasets, setting this to true may slow down the training process.
When using either a smaller dataset or a restricted depth, this may
speed up the training.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id6"><span class="problematic" id="id7">feature_importances_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array of shape = [n_features]</span></dt>
<dd>The feature importances.
The higher, the more important the feature.
The importance of a feature is computed as the
(normalized) total reduction of the criterion brought
by that feature. It is also known as the Gini importance <a class="footnote-reference" href="#id5" id="id1">[4]</a>.</dd>
<dt><a href="#id8"><span class="problematic" id="id9">max_features_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int,</span></dt>
<dd>The inferred value of max_features.</dd>
<dt><a href="#id10"><span class="problematic" id="id11">n_features_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>The number of features when <code class="docutils literal"><span class="pre">fit</span></code> is performed.</dd>
<dt><a href="#id12"><span class="problematic" id="id13">n_outputs_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>The number of outputs when <code class="docutils literal"><span class="pre">fit</span></code> is performed.</dd>
<dt><a href="#id14"><span class="problematic" id="id15">tree_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">Tree object</span></dt>
<dd>The underlying Tree object.</dd>
</dl>
<p>DecisionTreeClassifier</p>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><a class="reference external" href="http://en.wikipedia.org/wiki/Decision_tree_learning">http://en.wikipedia.org/wiki/Decision_tree_learning</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td>L. Breiman, J. Friedman, R. Olshen, and C. Stone, &#8220;Classification
and Regression Trees&#8221;, Wadsworth, Belmont, CA, 1984.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[3]</td><td>T. Hastie, R. Tibshirani and J. Friedman. &#8220;Elements of Statistical
Learning&#8221;, Springer, 2009.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id5" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[4]</a></td><td>L. Breiman, and A. Cutler, &#8220;Random Forests&#8221;,
<a class="reference external" href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm</a></td></tr>
</tbody>
</table>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regressor</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">... </span>                   
<span class="gp">...</span>
<span class="go">array([ 0.61..., 0.57..., -0.34..., 0.41..., 0.75...,</span>
<span class="go">        0.07..., 0.29..., 0.33..., -1.42..., -1.77...])</span>
</pre></div>
</div>
<dl class="method">
<dt id="sklearn.tree.DecisionTreeRegressor.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>criterion='mse'</em>, <em>splitter='best'</em>, <em>max_depth=None</em>, <em>min_samples_split=2</em>, <em>min_samples_leaf=1</em>, <em>min_weight_fraction_leaf=0.0</em>, <em>max_features=None</em>, <em>random_state=None</em>, <em>max_leaf_nodes=None</em>, <em>presort=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sklearn/tree/tree.html#DecisionTreeRegressor.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.__init__" title="sklearn.tree.DecisionTreeRegressor.__init__"><code class="xref py py-obj docutils literal"><span class="pre">__init__</span></code></a>([criterion,&nbsp;splitter,&nbsp;max_depth,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">apply</span></code>(X[,&nbsp;check_input])</td>
<td>Returns the index of the leaf that each sample is predicted as.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code>(X,&nbsp;y[,&nbsp;sample_weight,&nbsp;check_input,&nbsp;...])</td>
<td>Build a decision tree from the training set (X, y).</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code>(X[,&nbsp;check_input])</td>
<td>Predict class or regression value for X.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">score</span></code>(X,&nbsp;y[,&nbsp;sample_weight])</td>
<td>Returns the coefficient of determination R^2 of the prediction.</td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code>(*args,&nbsp;**kwargs)</td>
<td>DEPRECATED: Support to use estimators as feature selectors will be removed in version 0.19.</td>
</tr>
</tbody>
</table>
<p class="rubric">Attributes</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">feature_importances_</span></code></td>
<td>Return the feature importances.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2016, Russell Nakamura.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>