<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>sklearn.cross_validation &mdash; Predicting Boston Housing Prices 2016.02.21 documentation</title>
    
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/bootswatch-3.3.4/spacelab/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '2016.02.21',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../../_static/bootstrap-3.3.4/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="Predicting Boston Housing Prices 2016.02.21 documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html">
          Predicting Boston Housing Prices</a>
        <span class="navbar-text navbar-version pull-left"><b>2016.02.21</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../statistical_analysis.html"> Statistical Analysis and Data Exploration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../evaluating_model_performance.html"> Evaluating Model Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analyzing_model_performance.html"> Analyzing Model Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_prediction.html"> Model Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../citations.html"> Citations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software.html"> Software References</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"></ul>
</li>
              
            
            
              
                
              
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <h1>Source code for sklearn.cross_validation</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The :mod:`sklearn.cross_validation` module includes utilities for cross-</span>
<span class="sd">validation and performance evaluation.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;,</span>
<span class="c1">#         Gael Varoquaux &lt;gael.varoquaux@normalesup.org&gt;,</span>
<span class="c1">#         Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span><span class="p">,</span> <span class="n">combinations</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">ceil</span><span class="p">,</span> <span class="n">floor</span><span class="p">,</span> <span class="n">factorial</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="kn">as</span> <span class="nn">sp</span>

<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">is_classifier</span><span class="p">,</span> <span class="n">clone</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">indexable</span><span class="p">,</span> <span class="n">check_random_state</span><span class="p">,</span> <span class="n">safe_indexing</span>
<span class="kn">from</span> <span class="nn">.utils.validation</span> <span class="kn">import</span> <span class="p">(</span><span class="n">_is_arraylike</span><span class="p">,</span> <span class="n">_num_samples</span><span class="p">,</span>
                               <span class="n">check_array</span><span class="p">,</span> <span class="n">column_or_1d</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">.utils.multiclass</span> <span class="kn">import</span> <span class="n">type_of_target</span>
<span class="kn">from</span> <span class="nn">.externals.joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span><span class="p">,</span> <span class="n">logger</span>
<span class="kn">from</span> <span class="nn">.externals.six</span> <span class="kn">import</span> <span class="n">with_metaclass</span>
<span class="kn">from</span> <span class="nn">.externals.six.moves</span> <span class="kn">import</span> <span class="nb">zip</span>
<span class="kn">from</span> <span class="nn">.metrics.scorer</span> <span class="kn">import</span> <span class="n">check_scoring</span>
<span class="kn">from</span> <span class="nn">.utils.fixes</span> <span class="kn">import</span> <span class="n">bincount</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;KFold&#39;</span><span class="p">,</span>
           <span class="s1">&#39;LabelKFold&#39;</span><span class="p">,</span>
           <span class="s1">&#39;LeaveOneLabelOut&#39;</span><span class="p">,</span>
           <span class="s1">&#39;LeaveOneOut&#39;</span><span class="p">,</span>
           <span class="s1">&#39;LeavePLabelOut&#39;</span><span class="p">,</span>
           <span class="s1">&#39;LeavePOut&#39;</span><span class="p">,</span>
           <span class="s1">&#39;ShuffleSplit&#39;</span><span class="p">,</span>
           <span class="s1">&#39;StratifiedKFold&#39;</span><span class="p">,</span>
           <span class="s1">&#39;StratifiedShuffleSplit&#39;</span><span class="p">,</span>
           <span class="s1">&#39;PredefinedSplit&#39;</span><span class="p">,</span>
           <span class="s1">&#39;LabelShuffleSplit&#39;</span><span class="p">,</span>
           <span class="s1">&#39;check_cv&#39;</span><span class="p">,</span>
           <span class="s1">&#39;cross_val_score&#39;</span><span class="p">,</span>
           <span class="s1">&#39;cross_val_predict&#39;</span><span class="p">,</span>
           <span class="s1">&#39;permutation_test_score&#39;</span><span class="p">,</span>
           <span class="s1">&#39;train_test_split&#39;</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">_PartitionIterator</span><span class="p">(</span><span class="n">with_metaclass</span><span class="p">(</span><span class="n">ABCMeta</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot;Base class for CV iterators where train_mask = ~test_mask</span>

<span class="sd">    Implementations must define `_iter_test_masks` or `_iter_test_indices`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">        Total number of elements in dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;n must be an integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_test_masks</span><span class="p">():</span>
            <span class="n">train_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">test_index</span><span class="p">)</span>
            <span class="n">train_index</span> <span class="o">=</span> <span class="n">ind</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="n">ind</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
            <span class="k">yield</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span>

    <span class="c1"># Since subclasses must implement either _iter_test_masks or</span>
    <span class="c1"># _iter_test_indices, neither can be abstract.</span>
    <span class="k">def</span> <span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generates boolean masks corresponding to test sets.</span>

<span class="sd">        By default, delegates to _iter_test_indices()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_test_indices</span><span class="p">():</span>
            <span class="n">test_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_empty_mask</span><span class="p">()</span>
            <span class="n">test_mask</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="k">yield</span> <span class="n">test_mask</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generates integer indices corresponding to test sets.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">_empty_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">LeaveOneOut</span><span class="p">(</span><span class="n">_PartitionIterator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Leave-One-Out cross validation iterator.</span>

<span class="sd">    Provides train/test indices to split data in train test sets. Each</span>
<span class="sd">    sample is used once as a test set (singleton) while the remaining</span>
<span class="sd">    samples form the training set.</span>

<span class="sd">    Note: ``LeaveOneOut(n)`` is equivalent to ``KFold(n, n_folds=n)`` and</span>
<span class="sd">    ``LeavePOut(n, p=1)``.</span>

<span class="sd">    Due to the high number of test sets (which is the same as the</span>
<span class="sd">    number of samples) this cross validation method can be very costly.</span>
<span class="sd">    For large datasets one should favor KFold, StratifiedKFold or</span>
<span class="sd">    ShuffleSplit.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">        Total number of elements in dataset.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import cross_validation</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2])</span>
<span class="sd">    &gt;&gt;&gt; loo = cross_validation.LeaveOneOut(2)</span>
<span class="sd">    &gt;&gt;&gt; len(loo)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(loo)</span>
<span class="sd">    sklearn.cross_validation.LeaveOneOut(n=2)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in loo:</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...    X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...    y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    ...    print(X_train, X_test, y_train, y_test)</span>
<span class="sd">    TRAIN: [1] TEST: [0]</span>
<span class="sd">    [[3 4]] [[1 2]] [2] [1]</span>
<span class="sd">    TRAIN: [0] TEST: [1]</span>
<span class="sd">    [[1 2]] [[3 4]] [1] [2]</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    LeaveOneLabelOut for splitting the data according to explicit,</span>
<span class="sd">    domain-specific stratification of the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1">(n=</span><span class="si">%i</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__module__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>


<span class="k">class</span> <span class="nc">LeavePOut</span><span class="p">(</span><span class="n">_PartitionIterator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Leave-P-Out cross validation iterator</span>

<span class="sd">    Provides train/test indices to split data in train test sets. This results</span>
<span class="sd">    in testing on all distinct samples of size p, while the remaining n - p</span>
<span class="sd">    samples form the training set in each iteration.</span>

<span class="sd">    Note: ``LeavePOut(n, p)`` is NOT equivalent to ``KFold(n, n_folds=n // p)``</span>
<span class="sd">    which creates non-overlapping test sets.</span>

<span class="sd">    Due to the high number of iterations which grows combinatorically with the</span>
<span class="sd">    number of samples this cross validation method can be very costly. For</span>
<span class="sd">    large datasets one should favor KFold, StratifiedKFold or ShuffleSplit.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">        Total number of elements in dataset.</span>

<span class="sd">    p : int</span>
<span class="sd">        Size of the test sets.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import cross_validation</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; lpo = cross_validation.LeavePOut(4, 2)</span>
<span class="sd">    &gt;&gt;&gt; len(lpo)</span>
<span class="sd">    6</span>
<span class="sd">    &gt;&gt;&gt; print(lpo)</span>
<span class="sd">    sklearn.cross_validation.LeavePOut(n=4, p=2)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in lpo:</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...    X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...    y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [2 3] TEST: [0 1]</span>
<span class="sd">    TRAIN: [1 3] TEST: [0 2]</span>
<span class="sd">    TRAIN: [1 2] TEST: [0 3]</span>
<span class="sd">    TRAIN: [0 3] TEST: [1 2]</span>
<span class="sd">    TRAIN: [0 2] TEST: [1 3]</span>
<span class="sd">    TRAIN: [0 1] TEST: [2 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeavePOut</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">comb</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">comb</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1">(n=</span><span class="si">%i</span><span class="s1">, p=</span><span class="si">%i</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__module__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">factorial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">factorial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
                   <span class="o">/</span> <span class="n">factorial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">_BaseKFold</span><span class="p">(</span><span class="n">with_metaclass</span><span class="p">(</span><span class="n">ABCMeta</span><span class="p">,</span> <span class="n">_PartitionIterator</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot;Base class to validate KFold approaches&quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">n_folds</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_folds</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;n_folds must be an integer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span> <span class="o">=</span> <span class="n">n_folds</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_folds</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_folds</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;k-fold cross validation requires at least one&quot;</span>
                <span class="s2">&quot; train / test split by setting n_folds=2 or more,&quot;</span>
                <span class="s2">&quot; got n_folds={0}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_folds</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">n_folds</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;Cannot have number of folds n_folds={0} greater&quot;</span>
                 <span class="s2">&quot; than the number of samples: {1}.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_folds</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shuffle</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;shuffle must be True or False;&quot;</span>
                            <span class="s2">&quot; got {0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">shuffle</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>


<span class="k">class</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;K-Folds cross validation iterator.</span>

<span class="sd">    Provides train/test indices to split data in train test sets. Split</span>
<span class="sd">    dataset into k consecutive folds (without shuffling by default).</span>

<span class="sd">    Each fold is then used a validation set once while the k - 1 remaining</span>
<span class="sd">    fold form the training set.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">        Total number of elements.</span>

<span class="sd">    n_folds : int, default=3</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">    shuffle : boolean, optional</span>
<span class="sd">        Whether to shuffle the data before splitting into batches.</span>

<span class="sd">    random_state : None, int or RandomState</span>
<span class="sd">        When shuffle=True, pseudo-random number generator state used for</span>
<span class="sd">        shuffling. If None, use default numpy RNG for shuffling.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.cross_validation import KFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; kf = KFold(4, n_folds=2)</span>
<span class="sd">    &gt;&gt;&gt; len(kf)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(kf)  # doctest: +NORMALIZE_WHITESPACE</span>
<span class="sd">    sklearn.cross_validation.KFold(n=4, n_folds=2, shuffle=False,</span>
<span class="sd">                                   random_state=None)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in kf:</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...    X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...    y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [2 3] TEST: [0 1]</span>
<span class="sd">    TRAIN: [0 1] TEST: [2 3]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The first n % n_folds folds have size n // n_folds + 1, other folds have</span>
<span class="sd">    size n // n_folds.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    StratifiedKFold: take label information into account to avoid building</span>
<span class="sd">    folds with imbalanced class distributions (for binary or multiclass</span>
<span class="sd">    classification tasks).</span>

<span class="sd">    LabelKFold: K-fold iterator variant with non-overlapping labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">KFold</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">rng</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idxs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>
        <span class="n">n_folds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span>
        <span class="n">fold_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span> <span class="o">//</span> <span class="n">n_folds</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_folds</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="n">fold_sizes</span><span class="p">[:</span><span class="n">n</span> <span class="o">%</span> <span class="n">n_folds</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">current</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">fold_size</span> <span class="ow">in</span> <span class="n">fold_sizes</span><span class="p">:</span>
            <span class="n">start</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">current</span><span class="p">,</span> <span class="n">current</span> <span class="o">+</span> <span class="n">fold_size</span>
            <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">idxs</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">]</span>
            <span class="n">current</span> <span class="o">=</span> <span class="n">stop</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1">(n=</span><span class="si">%i</span><span class="s1">, n_folds=</span><span class="si">%i</span><span class="s1">, shuffle=</span><span class="si">%s</span><span class="s1">, random_state=</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__module__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span>


<span class="k">class</span> <span class="nc">LabelKFold</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;K-fold iterator variant with non-overlapping labels.</span>

<span class="sd">    The same label will not appear in two different folds (the number of</span>
<span class="sd">    distinct labels has to be at least equal to the number of folds).</span>

<span class="sd">    The folds are approximately balanced in the sense that the number of</span>
<span class="sd">    distinct labels is approximately the same in each fold.</span>

<span class="sd">    .. versionadded:: 0.17</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    labels : array-like with shape (n_samples, )</span>
<span class="sd">        Contains a label for each sample.</span>
<span class="sd">        The folds are built so that the same label does not appear in two</span>
<span class="sd">        different folds.</span>

<span class="sd">    n_folds : int, default=3</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.cross_validation import LabelKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; labels = np.array([0, 0, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; label_kfold = LabelKFold(labels, n_folds=2)</span>
<span class="sd">    &gt;&gt;&gt; len(label_kfold)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(label_kfold)</span>
<span class="sd">    sklearn.cross_validation.LabelKFold(n_labels=4, n_folds=2)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in label_kfold:</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    ...     print(X_train, X_test, y_train, y_test)</span>
<span class="sd">    ...</span>
<span class="sd">    TRAIN: [0 1] TEST: [2 3]</span>
<span class="sd">    [[1 2]</span>
<span class="sd">     [3 4]] [[5 6]</span>
<span class="sd">     [7 8]] [1 2] [3 4]</span>
<span class="sd">    TRAIN: [2 3] TEST: [0 1]</span>
<span class="sd">    [[5 6]</span>
<span class="sd">     [7 8]] [[1 2]</span>
<span class="sd">     [3 4]] [3 4] [1 2]</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    LeaveOneLabelOut for splitting the data according to explicit,</span>
<span class="sd">    domain-specific stratification of the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LabelKFold</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="n">n_folds</span><span class="p">,</span>
                                         <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

        <span class="n">unique_labels</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">n_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_folds</span> <span class="o">&gt;</span> <span class="n">n_labels</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span><span class="s2">&quot;Cannot have number of folds n_folds={0} greater&quot;</span>
                     <span class="s2">&quot; than the number of labels: {1}.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_folds</span><span class="p">,</span>
                                                                <span class="n">n_labels</span><span class="p">))</span>

        <span class="c1"># Weight labels by their number of occurences</span>
        <span class="n">n_samples_per_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Distribute the most frequent labels first</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">n_samples_per_label</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">n_samples_per_label</span> <span class="o">=</span> <span class="n">n_samples_per_label</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

        <span class="c1"># Total weight of each fold</span>
        <span class="n">n_samples_per_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_folds</span><span class="p">)</span>

        <span class="c1"># Mapping from label index to fold index</span>
        <span class="n">label_to_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">))</span>

        <span class="c1"># Distribute samples by adding the largest weight to the lightest fold</span>
        <span class="k">for</span> <span class="n">label_index</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_samples_per_label</span><span class="p">):</span>
            <span class="n">lightest_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">n_samples_per_fold</span><span class="p">)</span>
            <span class="n">n_samples_per_fold</span><span class="p">[</span><span class="n">lightest_fold</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weight</span>
            <span class="n">label_to_fold</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">label_index</span><span class="p">]]</span> <span class="o">=</span> <span class="n">lightest_fold</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">idxs</span> <span class="o">=</span> <span class="n">label_to_fold</span><span class="p">[</span><span class="n">labels</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idxs</span> <span class="o">==</span> <span class="n">f</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;{0}.{1}(n_labels={2}, n_folds={3})&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__module__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span>


<span class="k">class</span> <span class="nc">StratifiedKFold</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stratified K-Folds cross validation iterator</span>

<span class="sd">    Provides train/test indices to split data in train test sets.</span>

<span class="sd">    This cross-validation object is a variation of KFold that</span>
<span class="sd">    returns stratified folds. The folds are made by preserving</span>
<span class="sd">    the percentage of samples for each class.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y : array-like, [n_samples]</span>
<span class="sd">        Samples to split in K folds.</span>

<span class="sd">    n_folds : int, default=3</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">    shuffle : boolean, optional</span>
<span class="sd">        Whether to shuffle each stratification of the data before splitting</span>
<span class="sd">        into batches.</span>

<span class="sd">    random_state : None, int or RandomState</span>
<span class="sd">        When shuffle=True, pseudo-random number generator state used for</span>
<span class="sd">        shuffling. If None, use default numpy RNG for shuffling.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.cross_validation import StratifiedKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; skf = StratifiedKFold(y, n_folds=2)</span>
<span class="sd">    &gt;&gt;&gt; len(skf)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(skf)  # doctest: +NORMALIZE_WHITESPACE</span>
<span class="sd">    sklearn.cross_validation.StratifiedKFold(labels=[0 0 1 1], n_folds=2,</span>
<span class="sd">                                             shuffle=False, random_state=None)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in skf:</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...    X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...    y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [1 3] TEST: [0 2]</span>
<span class="sd">    TRAIN: [0 2] TEST: [1 3]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    All the folds have size trunc(n_samples / n_folds), the last one has the</span>
<span class="sd">    complementary.</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    LabelKFold: K-fold iterator variant with non-overlapping labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StratifiedKFold</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">n_folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">unique_labels</span><span class="p">,</span> <span class="n">y_inversed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">label_counts</span> <span class="o">=</span> <span class="n">bincount</span><span class="p">(</span><span class="n">y_inversed</span><span class="p">)</span>
        <span class="n">min_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">label_counts</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span> <span class="o">&gt;</span> <span class="n">min_labels</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">((</span><span class="s2">&quot;The least populated class in y has only </span><span class="si">%d</span><span class="s2">&quot;</span>
                           <span class="s2">&quot; members, which is too few. The minimum&quot;</span>
                           <span class="s2">&quot; number of labels for any class cannot&quot;</span>
                           <span class="s2">&quot; be less than n_folds=</span><span class="si">%d</span><span class="s2">.&quot;</span>
                           <span class="o">%</span> <span class="p">(</span><span class="n">min_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">)),</span> <span class="ne">Warning</span><span class="p">)</span>

        <span class="c1"># don&#39;t want to use the same seed in each label&#39;s shuffle</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span>

        <span class="c1"># pre-assign each sample to a test fold index using individual KFold</span>
        <span class="c1"># splitting strategies for each label so as to respect the</span>
        <span class="c1"># balance of labels</span>
        <span class="n">per_label_cvs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">KFold</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">,</span>
                  <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">label_counts</span><span class="p">]</span>
        <span class="n">test_folds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">test_fold_idx</span><span class="p">,</span> <span class="n">per_label_splits</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">per_label_cvs</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">test_split</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">,</span> <span class="n">per_label_splits</span><span class="p">):</span>
                <span class="n">label_test_folds</span> <span class="o">=</span> <span class="n">test_folds</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">]</span>
                <span class="c1"># the test split can be too big because we used</span>
                <span class="c1"># KFold(max(c, self.n_folds), self.n_folds) instead of</span>
                <span class="c1"># KFold(c, self.n_folds) to make it possible to not crash even</span>
                <span class="c1"># if the data is not 100% stratifiable for all the labels</span>
                <span class="c1"># (we use a warning instead of raising an exception)</span>
                <span class="c1"># If this is the case, let&#39;s trim it:</span>
                <span class="n">test_split</span> <span class="o">=</span> <span class="n">test_split</span><span class="p">[</span><span class="n">test_split</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_test_folds</span><span class="p">)]</span>
                <span class="n">label_test_folds</span><span class="p">[</span><span class="n">test_split</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_fold_idx</span>
                <span class="n">test_folds</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_test_folds</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">test_folds</span> <span class="o">=</span> <span class="n">test_folds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">):</span>
            <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_folds</span> <span class="o">==</span> <span class="n">i</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1">(labels=</span><span class="si">%s</span><span class="s1">, n_folds=</span><span class="si">%i</span><span class="s1">, shuffle=</span><span class="si">%s</span><span class="s1">, random_state=</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__module__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span>


<span class="k">class</span> <span class="nc">LeaveOneLabelOut</span><span class="p">(</span><span class="n">_PartitionIterator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Leave-One-Label_Out cross-validation iterator</span>

<span class="sd">    Provides train/test indices to split data according to a third-party</span>
<span class="sd">    provided label. This label information can be used to encode arbitrary</span>
<span class="sd">    domain specific stratifications of the samples as integers.</span>

<span class="sd">    For instance the labels could be the year of collection of the samples</span>
<span class="sd">    and thus allow for cross-validation against time-based splits.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    labels : array-like of int with shape (n_samples,)</span>
<span class="sd">        Arbitrary domain-specific stratification of the data to be used</span>
<span class="sd">        to draw the splits.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import cross_validation</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 1, 2])</span>
<span class="sd">    &gt;&gt;&gt; labels = np.array([1, 1, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; lol = cross_validation.LeaveOneLabelOut(labels)</span>
<span class="sd">    &gt;&gt;&gt; len(lol)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(lol)</span>
<span class="sd">    sklearn.cross_validation.LeaveOneLabelOut(labels=[1 1 2 2])</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in lol:</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...    X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...    y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    ...    print(X_train, X_test, y_train, y_test)</span>
<span class="sd">    TRAIN: [2 3] TEST: [0 1]</span>
<span class="sd">    [[5 6]</span>
<span class="sd">     [7 8]] [[1 2]</span>
<span class="sd">     [3 4]] [1 2] [1 2]</span>
<span class="sd">    TRAIN: [0 1] TEST: [2 3]</span>
<span class="sd">    [[1 2]</span>
<span class="sd">     [3 4]] [[5 6]</span>
<span class="sd">     [7 8]] [1 2] [1 2]</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    LabelKFold: K-fold iterator variant with non-overlapping labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeaveOneLabelOut</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
        <span class="c1"># We make a copy of labels to avoid side-effects during iteration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unique_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_unique_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_labels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_labels</span><span class="p">:</span>
            <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">==</span> <span class="n">i</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1">(labels=</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__module__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_unique_labels</span>


<span class="k">class</span> <span class="nc">LeavePLabelOut</span><span class="p">(</span><span class="n">_PartitionIterator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Leave-P-Label_Out cross-validation iterator</span>

<span class="sd">    Provides train/test indices to split data according to a third-party</span>
<span class="sd">    provided label. This label information can be used to encode arbitrary</span>
<span class="sd">    domain specific stratifications of the samples as integers.</span>

<span class="sd">    For instance the labels could be the year of collection of the samples</span>
<span class="sd">    and thus allow for cross-validation against time-based splits.</span>

<span class="sd">    The difference between LeavePLabelOut and LeaveOneLabelOut is that</span>
<span class="sd">    the former builds the test sets with all the samples assigned to</span>
<span class="sd">    ``p`` different values of the labels while the latter uses samples</span>
<span class="sd">    all assigned the same labels.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    labels : array-like of int with shape (n_samples,)</span>
<span class="sd">        Arbitrary domain-specific stratification of the data to be used</span>
<span class="sd">        to draw the splits.</span>

<span class="sd">    p : int</span>
<span class="sd">        Number of samples to leave out in the test split.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import cross_validation</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 1])</span>
<span class="sd">    &gt;&gt;&gt; labels = np.array([1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; lpl = cross_validation.LeavePLabelOut(labels, p=2)</span>
<span class="sd">    &gt;&gt;&gt; len(lpl)</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; print(lpl)</span>
<span class="sd">    sklearn.cross_validation.LeavePLabelOut(labels=[1 2 3], p=2)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in lpl:</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...    X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...    y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    ...    print(X_train, X_test, y_train, y_test)</span>
<span class="sd">    TRAIN: [2] TEST: [0 1]</span>
<span class="sd">    [[5 6]] [[1 2]</span>
<span class="sd">     [3 4]] [1] [1 2]</span>
<span class="sd">    TRAIN: [1] TEST: [0 2]</span>
<span class="sd">    [[3 4]] [[1 2]</span>
<span class="sd">     [5 6]] [2] [1 1]</span>
<span class="sd">    TRAIN: [0] TEST: [1 2]</span>
<span class="sd">    [[1 2]] [[3 4]</span>
<span class="sd">     [5 6]] [1] [2 1]</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    LabelKFold: K-fold iterator variant with non-overlapping labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="c1"># We make a copy of labels to avoid side-effects during iteration</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeavePLabelOut</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unique_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_unique_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span> <span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">comb</span> <span class="o">=</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_unique_labels</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">comb</span><span class="p">:</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_empty_mask</span><span class="p">()</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="n">test_index</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">==</span> <span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="k">yield</span> <span class="n">test_index</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1">(labels=</span><span class="si">%s</span><span class="s1">, p=</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__module__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">factorial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_unique_labels</span><span class="p">)</span> <span class="o">/</span>
                   <span class="n">factorial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_unique_labels</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="o">/</span>
                   <span class="n">factorial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">BaseShuffleSplit</span><span class="p">(</span><span class="n">with_metaclass</span><span class="p">(</span><span class="n">ABCMeta</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot;Base class for ShuffleSplit and StratifiedShuffleSplit&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="o">=</span> <span class="n">test_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span> <span class="o">=</span> <span class="n">train_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_test</span> <span class="o">=</span> <span class="n">_validate_shuffle_split</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span>
                                                            <span class="n">train_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_indices</span><span class="p">():</span>
            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>
        <span class="k">return</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate (train, test) indices&quot;&quot;&quot;</span>


<span class="k">class</span> <span class="nc">ShuffleSplit</span><span class="p">(</span><span class="n">BaseShuffleSplit</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Random permutation cross-validation iterator.</span>

<span class="sd">    Yields indices to split data into training and test sets.</span>

<span class="sd">    Note: contrary to other cross-validation strategies, random splits</span>
<span class="sd">    do not guarantee that all folds will be different, although this is</span>
<span class="sd">    still very likely for sizeable datasets.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">        Total number of elements in the dataset.</span>

<span class="sd">    n_iter : int (default 10)</span>
<span class="sd">        Number of re-shuffling &amp; splitting iterations.</span>

<span class="sd">    test_size : float (default 0.1), int, or None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the test split. If</span>
<span class="sd">        int, represents the absolute number of test samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the train size.</span>

<span class="sd">    train_size : float, int, or None (default is None)</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int or RandomState</span>
<span class="sd">        Pseudo-random number generator state used for random sampling.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import cross_validation</span>
<span class="sd">    &gt;&gt;&gt; rs = cross_validation.ShuffleSplit(4, n_iter=3,</span>
<span class="sd">    ...     test_size=.25, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; len(rs)</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; print(rs)</span>
<span class="sd">    ... # doctest: +ELLIPSIS</span>
<span class="sd">    ShuffleSplit(4, n_iter=3, test_size=0.25, ...)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in rs:</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...</span>
<span class="sd">    TRAIN: [3 1 0] TEST: [2]</span>
<span class="sd">    TRAIN: [2 1 3] TEST: [0]</span>
<span class="sd">    TRAIN: [0 2 1] TEST: [3]</span>

<span class="sd">    &gt;&gt;&gt; rs = cross_validation.ShuffleSplit(4, n_iter=3,</span>
<span class="sd">    ...     train_size=0.5, test_size=.25, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in rs:</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...</span>
<span class="sd">    TRAIN: [3 1] TEST: [2]</span>
<span class="sd">    TRAIN: [2 1] TEST: [0]</span>
<span class="sd">    TRAIN: [0 2] TEST: [3]</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">):</span>
            <span class="c1"># random partition</span>
            <span class="n">permutation</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
            <span class="n">ind_test</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span><span class="p">]</span>
            <span class="n">ind_train</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_train</span><span class="p">]</span>
            <span class="k">yield</span> <span class="n">ind_train</span><span class="p">,</span> <span class="n">ind_test</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">(</span><span class="si">%d</span><span class="s1">, n_iter=</span><span class="si">%d</span><span class="s1">, test_size=</span><span class="si">%s</span><span class="s1">, &#39;</span>
                <span class="s1">&#39;random_state=</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span>
                    <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                <span class="p">))</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span>


<span class="k">def</span> <span class="nf">_validate_shuffle_split</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">train_size</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;test_size and train_size can not both be None&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="mf">1.</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;test_size=</span><span class="si">%f</span><span class="s1"> should be smaller &#39;</span>
                    <span class="s1">&#39;than 1.0 or be an integer&#39;</span> <span class="o">%</span> <span class="n">test_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;i&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;test_size=</span><span class="si">%d</span><span class="s1"> should be smaller &#39;</span>
                    <span class="s1">&#39;than the number of samples </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid value for test_size: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">test_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">train_size</span> <span class="o">&gt;=</span> <span class="mf">1.</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;train_size=</span><span class="si">%f</span><span class="s2"> should be smaller &quot;</span>
                                 <span class="s2">&quot;than 1.0 or be an integer&quot;</span> <span class="o">%</span> <span class="n">train_size</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span> <span class="ow">and</span> \
                    <span class="n">train_size</span> <span class="o">+</span> <span class="n">test_size</span> <span class="o">&gt;</span> <span class="mf">1.</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The sum of test_size and train_size = </span><span class="si">%f</span><span class="s1">, &#39;</span>
                                 <span class="s1">&#39;should be smaller than 1.0. Reduce &#39;</span>
                                 <span class="s1">&#39;test_size and/or train_size.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">train_size</span> <span class="o">+</span> <span class="n">test_size</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;i&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">train_size</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;train_size=</span><span class="si">%d</span><span class="s2"> should be smaller &quot;</span>
                                 <span class="s2">&quot;than the number of samples </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid value for train_size: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">train_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span><span class="p">:</span>
        <span class="n">n_test</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">test_size</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;i&#39;</span><span class="p">:</span>
        <span class="n">n_test</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">n_train</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="n">n_test</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span><span class="p">:</span>
            <span class="n">n_train</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">train_size</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_train</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">n_test</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="n">n_train</span>

    <span class="k">if</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The sum of train_size and test_size = </span><span class="si">%d</span><span class="s1">, &#39;</span>
                         <span class="s1">&#39;should be smaller than the number of &#39;</span>
                         <span class="s1">&#39;samples </span><span class="si">%d</span><span class="s1">. Reduce test_size and/or &#39;</span>
                         <span class="s1">&#39;train_size.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_train</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_test</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">BaseShuffleSplit</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stratified ShuffleSplit cross validation iterator</span>

<span class="sd">    Provides train/test indices to split data in train test sets.</span>

<span class="sd">    This cross-validation object is a merge of StratifiedKFold and</span>
<span class="sd">    ShuffleSplit, which returns stratified randomized folds. The folds</span>
<span class="sd">    are made by preserving the percentage of samples for each class.</span>

<span class="sd">    Note: like the ShuffleSplit strategy, stratified random splits</span>
<span class="sd">    do not guarantee that all folds will be different, although this is</span>
<span class="sd">    still very likely for sizeable datasets.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y : array, [n_samples]</span>
<span class="sd">        Labels of samples.</span>

<span class="sd">    n_iter : int (default 10)</span>
<span class="sd">        Number of re-shuffling &amp; splitting iterations.</span>

<span class="sd">    test_size : float (default 0.1), int, or None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the test split. If</span>
<span class="sd">        int, represents the absolute number of test samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the train size.</span>

<span class="sd">    train_size : float, int, or None (default is None)</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int or RandomState</span>
<span class="sd">        Pseudo-random number generator state used for random sampling.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.cross_validation import StratifiedShuffleSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; sss = StratifiedShuffleSplit(y, 3, test_size=0.5, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; len(sss)</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; print(sss)       # doctest: +ELLIPSIS</span>
<span class="sd">    StratifiedShuffleSplit(labels=[0 0 1 1], n_iter=3, ...)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in sss:</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...    X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...    y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [1 2] TEST: [3 0]</span>
<span class="sd">    TRAIN: [0 2] TEST: [1 3]</span>
<span class="sd">    TRAIN: [0 2] TEST: [3 1]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">StratifiedShuffleSplit</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">train_size</span><span class="p">,</span> <span class="n">random_state</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">n_cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">bincount</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_indices</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The least populated class in y has only 1&quot;</span>
                             <span class="s2">&quot; member, which is too few. The minimum&quot;</span>
                             <span class="s2">&quot; number of labels for any class cannot&quot;</span>
                             <span class="s2">&quot; be less than 2.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_train</span> <span class="o">&lt;</span> <span class="n">n_cls</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The train_size = </span><span class="si">%d</span><span class="s1"> should be greater or &#39;</span>
                             <span class="s1">&#39;equal to the number of classes = </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_cls</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_test</span> <span class="o">&lt;</span> <span class="n">n_cls</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The test_size = </span><span class="si">%d</span><span class="s1"> should be greater or &#39;</span>
                             <span class="s1">&#39;equal to the number of classes = </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span><span class="p">,</span> <span class="n">n_cls</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">cls_count</span> <span class="o">=</span> <span class="n">bincount</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_indices</span><span class="p">)</span>
        <span class="n">p_i</span> <span class="o">=</span> <span class="n">cls_count</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
        <span class="n">n_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_train</span> <span class="o">*</span> <span class="n">p_i</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">t_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">cls_count</span> <span class="o">-</span> <span class="n">n_i</span><span class="p">,</span>
                         <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span> <span class="o">*</span> <span class="n">p_i</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">):</span>
            <span class="n">train</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">test</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cls</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">):</span>
                <span class="n">permutation</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">cls_count</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">cls_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">==</span> <span class="n">cls</span><span class="p">))[</span><span class="mi">0</span><span class="p">][</span><span class="n">permutation</span><span class="p">]</span>

                <span class="n">train</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">cls_i</span><span class="p">[:</span><span class="n">n_i</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
                <span class="n">test</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">cls_i</span><span class="p">[</span><span class="n">n_i</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span><span class="n">n_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">t_i</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>

            <span class="c1"># Because of rounding issues (as n_train and n_test are not</span>
            <span class="c1"># dividers of the number of elements per class), we may end</span>
            <span class="c1"># up here with less samples in train and test than asked for.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_train</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_test</span><span class="p">:</span>
                <span class="c1"># We complete by affecting randomly the missing indexes</span>
                <span class="n">missing_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">bincount</span><span class="p">(</span><span class="n">train</span> <span class="o">+</span> <span class="n">test</span><span class="p">,</span>
                                                <span class="n">minlength</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>
                                       <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">missing_idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">missing_idx</span><span class="p">)</span>
                <span class="n">train</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">missing_idx</span><span class="p">[:(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_train</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">))])</span>
                <span class="n">test</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">missing_idx</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">)):])</span>

            <span class="n">train</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
            <span class="n">test</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">(labels=</span><span class="si">%s</span><span class="s1">, n_iter=</span><span class="si">%d</span><span class="s1">, test_size=</span><span class="si">%s</span><span class="s1">, &#39;</span>
                <span class="s1">&#39;random_state=</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span>
                    <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                <span class="p">))</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span>


<span class="k">class</span> <span class="nc">PredefinedSplit</span><span class="p">(</span><span class="n">_PartitionIterator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predefined split cross validation iterator</span>

<span class="sd">    Splits the data into training/test set folds according to a predefined</span>
<span class="sd">    scheme. Each sample can be assigned to at most one test set fold, as</span>
<span class="sd">    specified by the user through the ``test_fold`` parameter.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    test_fold : &quot;array-like, shape (n_samples,)</span>
<span class="sd">        test_fold[i] gives the test set fold of sample i. A value of -1</span>
<span class="sd">        indicates that the corresponding sample is not part of any test set</span>
<span class="sd">        folds, but will instead always be put into the training fold.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.cross_validation import PredefinedSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; ps = PredefinedSplit(test_fold=[0, 1, -1, 1])</span>
<span class="sd">    &gt;&gt;&gt; len(ps)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(ps)       # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS</span>
<span class="sd">    sklearn.cross_validation.PredefinedSplit(test_fold=[ 0  1 -1  1])</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in ps:</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...    X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...    y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [1 2 3] TEST: [0]</span>
<span class="sd">    TRAIN: [0 2] TEST: [1 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_fold</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PredefinedSplit</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_fold</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_fold</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span> <span class="o">==</span> <span class="n">f</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1">(test_fold=</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__module__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">LabelShuffleSplit</span><span class="p">(</span><span class="n">ShuffleSplit</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Shuffle-Labels-Out cross-validation iterator</span>

<span class="sd">    Provides randomized train/test indices to split data according to a</span>
<span class="sd">    third-party provided label. This label information can be used to encode</span>
<span class="sd">    arbitrary domain specific stratifications of the samples as integers.</span>

<span class="sd">    For instance the labels could be the year of collection of the samples</span>
<span class="sd">    and thus allow for cross-validation against time-based splits.</span>

<span class="sd">    The difference between LeavePLabelOut and LabelShuffleSplit is that</span>
<span class="sd">    the former generates splits using all subsets of size ``p`` unique labels,</span>
<span class="sd">    whereas LabelShuffleSplit generates a user-determined number of random</span>
<span class="sd">    test splits, each with a user-determined fraction of unique labels.</span>

<span class="sd">    For example, a less computationally intensive alternative to</span>
<span class="sd">    ``LeavePLabelOut(labels, p=10)`` would be</span>
<span class="sd">    ``LabelShuffleSplit(labels, test_size=10, n_iter=100)``.</span>

<span class="sd">    Note: The parameters ``test_size`` and ``train_size`` refer to labels, and</span>
<span class="sd">    not to samples, as in ShuffleSplit.</span>

<span class="sd">    .. versionadded:: 0.17</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    labels :  array, [n_samples]</span>
<span class="sd">        Labels of samples</span>

<span class="sd">    n_iter : int (default 5)</span>
<span class="sd">        Number of re-shuffling and splitting iterations.</span>

<span class="sd">    test_size : float (default 0.2), int, or None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the labels to include in the test split. If</span>
<span class="sd">        int, represents the absolute number of test labels. If None,</span>
<span class="sd">        the value is automatically set to the complement of the train size.</span>

<span class="sd">    train_size : float, int, or None (default is None)</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the labels to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train labels. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int or RandomState</span>
<span class="sd">        Pseudo-random number generator state used for random sampling.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

        <span class="n">classes</span><span class="p">,</span> <span class="n">label_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">LabelShuffleSplit</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">),</span>
            <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span>
            <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
            <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="n">classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_indices</span> <span class="o">=</span> <span class="n">label_indices</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">(labels=</span><span class="si">%s</span><span class="s1">, n_iter=</span><span class="si">%d</span><span class="s1">, test_size=</span><span class="si">%s</span><span class="s1">, &#39;</span>
                <span class="s1">&#39;random_state=</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span>
                    <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
                <span class="p">))</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span>

    <span class="k">def</span> <span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">label_train</span><span class="p">,</span> <span class="n">label_test</span> <span class="ow">in</span> <span class="nb">super</span><span class="p">(</span><span class="n">LabelShuffleSplit</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">_iter_indices</span><span class="p">():</span>
            <span class="c1"># these are the indices of classes in the partition</span>
            <span class="c1"># invert them into data indices</span>

            <span class="n">train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">in1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_indices</span><span class="p">,</span> <span class="n">label_train</span><span class="p">))</span>
            <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">in1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_indices</span><span class="p">,</span> <span class="n">label_test</span><span class="p">))</span>

            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>


<span class="c1">##############################################################################</span>
<span class="k">def</span> <span class="nf">_index_param_value</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Private helper function for parameter value indexing.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_arraylike</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">or</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">!=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="c1"># pass through: skip indexing</span>
        <span class="k">return</span> <span class="n">v</span>
    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">tocsr</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">safe_indexing</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">cross_val_predict</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                      <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="s1">&#39;2*n_jobs&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate cross-validated estimates for each input data point</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object implementing &#39;fit&#39; and &#39;predict&#39;</span>
<span class="sd">        The object to use to fit the data.</span>

<span class="sd">    X : array-like</span>
<span class="sd">        The data to fit. Can be, for example a list, or an array at least 2d.</span>

<span class="sd">    y : array-like, optional, default: None</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - None, to use the default 3-fold cross-validation,</span>
<span class="sd">        - integer, to specify the number of folds.</span>
<span class="sd">        - An object to be used as a cross-validation generator.</span>
<span class="sd">        - An iterable yielding train/test splits.</span>

<span class="sd">        For integer/None inputs, if ``y`` is binary or multiclass,</span>
<span class="sd">        :class:`StratifiedKFold` used. If the estimator is a classifier</span>
<span class="sd">        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">    n_jobs : integer, optional</span>
<span class="sd">        The number of CPUs to use to do the computation. -1 means</span>
<span class="sd">        &#39;all CPUs&#39;.</span>

<span class="sd">    verbose : integer, optional</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    fit_params : dict, optional</span>
<span class="sd">        Parameters to pass to the fit method of the estimator.</span>

<span class="sd">    pre_dispatch : int, or string, optional</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">            - None, in which case all the jobs are immediately</span>
<span class="sd">              created and spawned. Use this for lightweight and</span>
<span class="sd">              fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">              spawning of the jobs</span>

<span class="sd">            - An int, giving the exact number of total jobs that are</span>
<span class="sd">              spawned</span>

<span class="sd">            - A string, giving an expression as a function of n_jobs,</span>
<span class="sd">              as in &#39;2*n_jobs&#39;</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    preds : ndarray</span>
<span class="sd">        This is the result of calling &#39;predict&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>
    <span class="c1"># We clone the estimator to make sure that all the folds are</span>
    <span class="c1"># independent, and that it is pickle-able.</span>
    <span class="n">parallel</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                        <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">)</span>
    <span class="n">preds_blocks</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span><span class="n">delayed</span><span class="p">(</span><span class="n">_fit_and_predict</span><span class="p">)(</span><span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                                                      <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span>
                                                      <span class="n">fit_params</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="p">)</span>

    <span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">preds_blocks</span><span class="p">]</span>
    <span class="n">locs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">loc</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">loc</span> <span class="ow">in</span> <span class="n">preds_blocks</span><span class="p">])</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_check_is_partition</span><span class="p">(</span><span class="n">locs</span><span class="p">,</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;cross_val_predict only works for partitions&#39;</span><span class="p">)</span>
    <span class="n">inv_locs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">locs</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">inv_locs</span><span class="p">[</span><span class="n">locs</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">locs</span><span class="p">))</span>

    <span class="c1"># Check for sparse predictions</span>
    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">preds</span><span class="p">[</span><span class="n">inv_locs</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_fit_and_predict</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">fit_params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fit estimator and predict values for a given dataset split.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object implementing &#39;fit&#39; and &#39;predict&#39;</span>
<span class="sd">        The object to use to fit the data.</span>

<span class="sd">    X : array-like of shape at least 2D</span>
<span class="sd">        The data to fit.</span>

<span class="sd">    y : array-like, optional, default: None</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    train : array-like, shape (n_train_samples,)</span>
<span class="sd">        Indices of training samples.</span>

<span class="sd">    test : array-like, shape (n_test_samples,)</span>
<span class="sd">        Indices of test samples.</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    fit_params : dict or None</span>
<span class="sd">        Parameters that will be passed to ``estimator.fit``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    preds : sequence</span>
<span class="sd">        Result of calling &#39;estimator.predict&#39;</span>

<span class="sd">    test : array-like</span>
<span class="sd">        This is the value of the test parameter</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Adjust length of sample weights</span>
    <span class="n">fit_params</span> <span class="o">=</span> <span class="n">fit_params</span> <span class="k">if</span> <span class="n">fit_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">fit_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">k</span><span class="p">,</span> <span class="n">_index_param_value</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">train</span><span class="p">))</span>
                      <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">fit_params</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>
    <span class="n">X_test</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_train</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">preds</span><span class="p">,</span> <span class="n">test</span>


<span class="k">def</span> <span class="nf">_check_is_partition</span><span class="p">(</span><span class="n">locs</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Check whether locs is a reordering of the array np.arange(n)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    locs : ndarray</span>
<span class="sd">        integer array to test</span>
<span class="sd">    n : int</span>
<span class="sd">        number of expected elements</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    is_partition : bool</span>
<span class="sd">        True iff sorted(locs) is range(n)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">locs</span><span class="p">)</span> <span class="o">!=</span> <span class="n">n</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">False</span>
    <span class="n">hit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
    <span class="n">hit</span><span class="p">[</span><span class="n">locs</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">hit</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">False</span>
    <span class="k">return</span> <span class="bp">True</span>


<span class="k">def</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fit_params</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="s1">&#39;2*n_jobs&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluate a score by cross-validation</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object implementing &#39;fit&#39;</span>
<span class="sd">        The object to use to fit the data.</span>

<span class="sd">    X : array-like</span>
<span class="sd">        The data to fit. Can be, for example a list, or an array at least 2d.</span>

<span class="sd">    y : array-like, optional, default: None</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    scoring : string, callable or None, optional, default: None</span>
<span class="sd">        A string (see model evaluation documentation) or</span>
<span class="sd">        a scorer callable object / function with signature</span>
<span class="sd">        ``scorer(estimator, X, y)``.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - None, to use the default 3-fold cross-validation,</span>
<span class="sd">        - integer, to specify the number of folds.</span>
<span class="sd">        - An object to be used as a cross-validation generator.</span>
<span class="sd">        - An iterable yielding train/test splits.</span>

<span class="sd">        For integer/None inputs, if ``y`` is binary or multiclass,</span>
<span class="sd">        :class:`StratifiedKFold` used. If the estimator is a classifier</span>
<span class="sd">        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">    n_jobs : integer, optional</span>
<span class="sd">        The number of CPUs to use to do the computation. -1 means</span>
<span class="sd">        &#39;all CPUs&#39;.</span>

<span class="sd">    verbose : integer, optional</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    fit_params : dict, optional</span>
<span class="sd">        Parameters to pass to the fit method of the estimator.</span>

<span class="sd">    pre_dispatch : int, or string, optional</span>
<span class="sd">        Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">        execution. Reducing this number can be useful to avoid an</span>
<span class="sd">        explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">        than CPUs can process. This parameter can be:</span>

<span class="sd">            - None, in which case all the jobs are immediately</span>
<span class="sd">              created and spawned. Use this for lightweight and</span>
<span class="sd">              fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">              spawning of the jobs</span>

<span class="sd">            - An int, giving the exact number of total jobs that are</span>
<span class="sd">              spawned</span>

<span class="sd">            - A string, giving an expression as a function of n_jobs,</span>
<span class="sd">              as in &#39;2*n_jobs&#39;</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    scores : array of float, shape=(len(list(cv)),)</span>
<span class="sd">        Array of scores of the estimator for each run of the cross validation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>
    <span class="n">scorer</span> <span class="o">=</span> <span class="n">check_scoring</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
    <span class="c1"># We clone the estimator to make sure that all the folds are</span>
    <span class="c1"># independent, and that it is pickle-able.</span>
    <span class="n">parallel</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                        <span class="n">pre_dispatch</span><span class="o">=</span><span class="n">pre_dispatch</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span><span class="n">delayed</span><span class="p">(</span><span class="n">_fit_and_score</span><span class="p">)(</span><span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scorer</span><span class="p">,</span>
                                              <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span>
                                              <span class="n">fit_params</span><span class="p">)</span>
                      <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scores</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">FitFailedWarning</span><span class="p">(</span><span class="ne">RuntimeWarning</span><span class="p">):</span>
    <span class="k">pass</span>


<span class="k">def</span> <span class="nf">_fit_and_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scorer</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span>
                   <span class="n">parameters</span><span class="p">,</span> <span class="n">fit_params</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                   <span class="n">return_parameters</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fit estimator and compute scores for a given dataset split.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object implementing &#39;fit&#39;</span>
<span class="sd">        The object to use to fit the data.</span>

<span class="sd">    X : array-like of shape at least 2D</span>
<span class="sd">        The data to fit.</span>

<span class="sd">    y : array-like, optional, default: None</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    scorer : callable</span>
<span class="sd">        A scorer callable object / function with signature</span>
<span class="sd">        ``scorer(estimator, X, y)``.</span>

<span class="sd">    train : array-like, shape (n_train_samples,)</span>
<span class="sd">        Indices of training samples.</span>

<span class="sd">    test : array-like, shape (n_test_samples,)</span>
<span class="sd">        Indices of test samples.</span>

<span class="sd">    verbose : integer</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    error_score : &#39;raise&#39; (default) or numeric</span>
<span class="sd">        Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">        If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">        FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">        step, which will always raise the error.</span>

<span class="sd">    parameters : dict or None</span>
<span class="sd">        Parameters to be set on the estimator.</span>

<span class="sd">    fit_params : dict or None</span>
<span class="sd">        Parameters that will be passed to ``estimator.fit``.</span>

<span class="sd">    return_train_score : boolean, optional, default: False</span>
<span class="sd">        Compute and return score on training set.</span>

<span class="sd">    return_parameters : boolean, optional, default: False</span>
<span class="sd">        Return parameters that has been used for the estimator.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    train_score : float, optional</span>
<span class="sd">        Score on training set, returned only if `return_train_score` is `True`.</span>

<span class="sd">    test_score : float</span>
<span class="sd">        Score on test set.</span>

<span class="sd">    n_test_samples : int</span>
<span class="sd">        Number of test samples.</span>

<span class="sd">    scoring_time : float</span>
<span class="sd">        Time spent for fitting and scoring in seconds.</span>

<span class="sd">    parameters : dict or None, optional</span>
<span class="sd">        The parameters that have been evaluated.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;no parameters to be set&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
                          <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;[CV] </span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="p">(</span><span class="mi">64</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">msg</span><span class="p">))</span> <span class="o">*</span> <span class="s1">&#39;.&#39;</span><span class="p">))</span>

    <span class="c1"># Adjust length of sample weights</span>
    <span class="n">fit_params</span> <span class="o">=</span> <span class="n">fit_params</span> <span class="k">if</span> <span class="n">fit_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">fit_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">k</span><span class="p">,</span> <span class="n">_index_param_value</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">train</span><span class="p">))</span>
                      <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">fit_params</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>

    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">parameters</span><span class="p">)</span>

    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>
    <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">train</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">y_train</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">error_score</span> <span class="o">==</span> <span class="s1">&#39;raise&#39;</span><span class="p">:</span>
            <span class="k">raise</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">error_score</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
            <span class="n">test_score</span> <span class="o">=</span> <span class="n">error_score</span>
            <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
                <span class="n">train_score</span> <span class="o">=</span> <span class="n">error_score</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Classifier fit failed. The score on this train-test&quot;</span>
                          <span class="s2">&quot; partition for these parameters will be set to </span><span class="si">%f</span><span class="s2">. &quot;</span>
                          <span class="s2">&quot;Details: </span><span class="se">\n</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">error_score</span><span class="p">,</span> <span class="n">e</span><span class="p">),</span> <span class="n">FitFailedWarning</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;error_score must be the string &#39;raise&#39; or a&quot;</span>
                             <span class="s2">&quot; numeric value. (Hint: if using &#39;raise&#39;, please&quot;</span>
                             <span class="s2">&quot; make sure that it has been spelled correctly.)&quot;</span>
                             <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">test_score</span> <span class="o">=</span> <span class="n">_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">scorer</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_train_score</span><span class="p">:</span>
            <span class="n">train_score</span> <span class="o">=</span> <span class="n">_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scorer</span><span class="p">)</span>

    <span class="n">scoring_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;, score=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">test_score</span>
    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">end_msg</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> -</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">logger</span><span class="o">.</span><span class="n">short_format_time</span><span class="p">(</span><span class="n">scoring_time</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;[CV] </span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">((</span><span class="mi">64</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">end_msg</span><span class="p">))</span> <span class="o">*</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">end_msg</span><span class="p">))</span>

    <span class="n">ret</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_score</span><span class="p">]</span> <span class="k">if</span> <span class="n">return_train_score</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">test_score</span><span class="p">,</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">scoring_time</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">return_parameters</span><span class="p">:</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ret</span>


<span class="k">def</span> <span class="nf">_safe_split</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">train_indices</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create subset of dataset and properly handle kernels.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">callable</span><span class="p">(</span><span class="n">estimator</span><span class="o">.</span><span class="n">kernel</span><span class="p">):</span>
        <span class="c1"># cannot compute the kernel values with custom function</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot use a custom kernel function. &quot;</span>
                         <span class="s2">&quot;Precompute the kernel matrix instead.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;_pairwise&quot;</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Precomputed kernels or affinity matrices have &quot;</span>
                             <span class="s2">&quot;to be passed as arrays or sparse matrices.&quot;</span><span class="p">)</span>
        <span class="n">X_subset</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;_pairwise&quot;</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
            <span class="c1"># X is a precomputed square kernel matrix</span>
            <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X should be a square kernel matrix&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">train_indices</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">X_subset</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">indices</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X_subset</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">train_indices</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_subset</span> <span class="o">=</span> <span class="n">safe_indexing</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">y_subset</span> <span class="o">=</span> <span class="n">safe_indexing</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_subset</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">return</span> <span class="n">X_subset</span><span class="p">,</span> <span class="n">y_subset</span>


<span class="k">def</span> <span class="nf">_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">scorer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the score of an estimator on a given test set.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">y_test</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">scorer</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">scorer</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;scoring must return a number, got </span><span class="si">%s</span><span class="s2"> (</span><span class="si">%s</span><span class="s2">) instead.&quot;</span>
                         <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">score</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">score</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">score</span>


<span class="k">def</span> <span class="nf">_permutation_test_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="p">,</span> <span class="n">scorer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Auxiliary function for permutation_test_score&quot;&quot;&quot;</span>
    <span class="n">avg_score</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="p">:</span>
        <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
        <span class="n">avg_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scorer</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">avg_score</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_shuffle</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a shuffled copy of y eventually shuffle among same labels.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">this_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">label</span><span class="p">)</span>
            <span class="n">ind</span><span class="p">[</span><span class="n">this_mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">ind</span><span class="p">[</span><span class="n">this_mask</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Input checker utility for building a CV in a user friendly way.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - None, to use the default 3-fold cross-validation,</span>
<span class="sd">        - integer, to specify the number of folds.</span>
<span class="sd">        - An object to be used as a cross-validation generator.</span>
<span class="sd">        - An iterable yielding train/test splits.</span>

<span class="sd">        For integer/None inputs, if ``y`` is binary or multiclass,</span>
<span class="sd">        :class:`StratifiedKFold` used. If the estimator is a classifier</span>
<span class="sd">        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">    X : array-like</span>
<span class="sd">        The data the cross-val object will be applied on.</span>

<span class="sd">    y : array-like</span>
<span class="sd">        The target variable for a supervised learning problem.</span>

<span class="sd">    classifier : boolean optional</span>
<span class="sd">        Whether the task is a classification task, in which case</span>
<span class="sd">        stratified KFold will be used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    checked_cv: a cross-validation generator instance.</span>
<span class="sd">        The return value is guaranteed to be a cv generator instance, whatever</span>
<span class="sd">        the input type.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">is_sparse</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cv</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">classifier</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;binary&#39;</span><span class="p">,</span> <span class="s1">&#39;multiclass&#39;</span><span class="p">]:</span>
                <span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">cv</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_sparse</span><span class="p">:</span>
                <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">cv</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cv</span>


<span class="k">def</span> <span class="nf">permutation_test_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                           <span class="n">n_permutations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                           <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluate the significance of a cross-validated score with permutations</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator object implementing &#39;fit&#39;</span>
<span class="sd">        The object to use to fit the data.</span>

<span class="sd">    X : array-like of shape at least 2D</span>
<span class="sd">        The data to fit.</span>

<span class="sd">    y : array-like</span>
<span class="sd">        The target variable to try to predict in the case of</span>
<span class="sd">        supervised learning.</span>

<span class="sd">    scoring : string, callable or None, optional, default: None</span>
<span class="sd">        A string (see model evaluation documentation) or</span>
<span class="sd">        a scorer callable object / function with signature</span>
<span class="sd">        ``scorer(estimator, X, y)``.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">        - None, to use the default 3-fold cross-validation,</span>
<span class="sd">        - integer, to specify the number of folds.</span>
<span class="sd">        - An object to be used as a cross-validation generator.</span>
<span class="sd">        - An iterable yielding train/test splits.</span>

<span class="sd">        For integer/None inputs, if ``y`` is binary or multiclass,</span>
<span class="sd">        :class:`StratifiedKFold` used. If the estimator is a classifier</span>
<span class="sd">        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">    n_permutations : integer, optional</span>
<span class="sd">        Number of times to permute ``y``.</span>

<span class="sd">    n_jobs : integer, optional</span>
<span class="sd">        The number of CPUs to use to do the computation. -1 means</span>
<span class="sd">        &#39;all CPUs&#39;.</span>

<span class="sd">    labels : array-like of shape [n_samples] (optional)</span>
<span class="sd">        Labels constrain the permutation among groups of samples with</span>
<span class="sd">        a same label.</span>

<span class="sd">    random_state : RandomState or an int seed (0 by default)</span>
<span class="sd">        A random number generator instance to define the state of the</span>
<span class="sd">        random permutations generator.</span>

<span class="sd">    verbose : integer, optional</span>
<span class="sd">        The verbosity level.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The true score without permuting targets.</span>

<span class="sd">    permutation_scores : array, shape (n_permutations,)</span>
<span class="sd">        The scores obtained for each permutations.</span>

<span class="sd">    pvalue : float</span>
<span class="sd">        The returned value equals p-value if `scoring` returns bigger</span>
<span class="sd">        numbers for better scores (e.g., accuracy_score). If `scoring` is</span>
<span class="sd">        rather a loss function (i.e. when lower is better such as with</span>
<span class="sd">        `mean_squared_error`) then this is actually the complement of the</span>
<span class="sd">        p-value:  1 - p-value.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function implements Test 1 in:</span>

<span class="sd">        Ojala and Garriga. Permutation Tests for Studying Classifier</span>
<span class="sd">        Performance.  The Journal of Machine Learning Research (2010)</span>
<span class="sd">        vol. 11</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>
    <span class="n">scorer</span> <span class="o">=</span> <span class="n">check_scoring</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="c1"># We clone the estimator to make sure that all the folds are</span>
    <span class="c1"># independent, and that it is pickle-able.</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">_permutation_test_score</span><span class="p">(</span><span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="p">,</span> <span class="n">scorer</span><span class="p">)</span>
    <span class="n">permutation_scores</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)(</span>
        <span class="n">delayed</span><span class="p">(</span><span class="n">_permutation_test_score</span><span class="p">)(</span>
            <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">_shuffle</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">random_state</span><span class="p">),</span> <span class="n">cv</span><span class="p">,</span>
            <span class="n">scorer</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_permutations</span><span class="p">))</span>
    <span class="n">permutation_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">permutation_scores</span><span class="p">)</span>
    <span class="n">pvalue</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">permutation_scores</span> <span class="o">&gt;=</span> <span class="n">score</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_permutations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">score</span><span class="p">,</span> <span class="n">permutation_scores</span><span class="p">,</span> <span class="n">pvalue</span>


<span class="n">permutation_test_score</span><span class="o">.</span><span class="n">__test__</span> <span class="o">=</span> <span class="bp">False</span>  <span class="c1"># to avoid a pb with nosetests</span>


<div class="viewcode-block" id="train_test_split"><a class="viewcode-back" href="../../api/sklearn.cross_validation.train_test_split.html#sklearn.cross_validation.train_test_split">[docs]</a><span class="k">def</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="o">*</span><span class="n">arrays</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Split arrays or matrices into random train and test subsets</span>

<span class="sd">    Quick utility that wraps input validation and</span>
<span class="sd">    ``next(iter(ShuffleSplit(n_samples)))`` and application to input</span>
<span class="sd">    data into a single call for splitting (and optionally subsampling)</span>
<span class="sd">    data in a oneliner.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    *arrays : sequence of indexables with same length / shape[0]</span>

<span class="sd">        allowed inputs are lists, numpy arrays, scipy-sparse</span>
<span class="sd">        matrices or pandas dataframes.</span>

<span class="sd">        .. versionadded:: 0.16</span>
<span class="sd">            preserves input type instead of always casting to numpy array.</span>

<span class="sd">    test_size : float, int, or None (default is None)</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the test split. If</span>
<span class="sd">        int, represents the absolute number of test samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the train size.</span>
<span class="sd">        If train size is also None, test size is set to 0.25.</span>

<span class="sd">    train_size : float, int, or None (default is None)</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int or RandomState</span>
<span class="sd">        Pseudo-random number generator state used for random sampling.</span>

<span class="sd">    stratify : array-like or None (default is None)</span>
<span class="sd">        If not None, data is split in a stratified fashion, using this as</span>
<span class="sd">        the labels array.</span>

<span class="sd">        .. versionadded:: 0.17</span>
<span class="sd">           *stratify* splitting</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    splitting : list, length = 2 * len(arrays),</span>
<span class="sd">        List containing train-test split of inputs.</span>

<span class="sd">        .. versionadded:: 0.16</span>
<span class="sd">            Output type is the same as the input type.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.cross_validation import train_test_split</span>
<span class="sd">    &gt;&gt;&gt; X, y = np.arange(10).reshape((5, 2)), range(5)</span>
<span class="sd">    &gt;&gt;&gt; X</span>
<span class="sd">    array([[0, 1],</span>
<span class="sd">           [2, 3],</span>
<span class="sd">           [4, 5],</span>
<span class="sd">           [6, 7],</span>
<span class="sd">           [8, 9]])</span>
<span class="sd">    &gt;&gt;&gt; list(y)</span>
<span class="sd">    [0, 1, 2, 3, 4]</span>

<span class="sd">    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(</span>
<span class="sd">    ...     X, y, test_size=0.33, random_state=42)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; X_train</span>
<span class="sd">    array([[4, 5],</span>
<span class="sd">           [0, 1],</span>
<span class="sd">           [6, 7]])</span>
<span class="sd">    &gt;&gt;&gt; y_train</span>
<span class="sd">    [2, 0, 3]</span>
<span class="sd">    &gt;&gt;&gt; X_test</span>
<span class="sd">    array([[2, 3],</span>
<span class="sd">           [8, 9]])</span>
<span class="sd">    &gt;&gt;&gt; y_test</span>
<span class="sd">    [1, 4]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_arrays</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">arrays</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_arrays</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At least one array required as input&quot;</span><span class="p">)</span>

    <span class="n">test_size</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;test_size&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="n">train_size</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;train_size&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;random_state&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;dtype&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;dtype option is ignored and will be removed in 0.18.&quot;</span><span class="p">,</span>
                      <span class="ne">DeprecationWarning</span><span class="p">)</span>

    <span class="n">allow_nd</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;allow_nd&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="n">allow_lists</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;allow_lists&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="n">stratify</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;stratify&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">allow_lists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;The allow_lists option is deprecated and will be &quot;</span>
                      <span class="s2">&quot;assumed True in 0.18 and removed.&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">options</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid parameters passed: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">options</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">allow_nd</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;The allow_nd option is deprecated and will be &quot;</span>
                      <span class="s2">&quot;assumed True in 0.18 and removed.&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">allow_lists</span> <span class="ow">is</span> <span class="bp">False</span> <span class="ow">or</span> <span class="n">allow_nd</span> <span class="ow">is</span> <span class="bp">False</span><span class="p">:</span>
        <span class="n">arrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">check_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;csr&#39;</span><span class="p">,</span> <span class="n">allow_nd</span><span class="o">=</span><span class="n">allow_nd</span><span class="p">,</span>
                              <span class="n">force_all_finite</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
                  <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">x</span>
                  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">arrays</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.25</span>
    <span class="n">arrays</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="o">*</span><span class="n">arrays</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">stratify</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">stratify</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
                                    <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
                                    <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
                          <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
                          <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">cv</span><span class="p">))</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">((</span><span class="n">safe_indexing</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">train</span><span class="p">),</span>
                                     <span class="n">safe_indexing</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">arrays</span><span class="p">))</span></div>


<span class="n">train_test_split</span><span class="o">.</span><span class="n">__test__</span> <span class="o">=</span> <span class="bp">False</span>  <span class="c1"># to avoid a pb with nosetests</span>
</pre></div>

    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2016, Russell Nakamura.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>