Statistical Analysis and Data Exploration
=========================================

<<name='imports', echo=False>>=
# third-party
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plot
import numpy
import pandas
import seaborn
import statsmodels.api as statsmodels

# this code
from boston_housing.common import load_housing_data, CLIENT_FEATURES
from boston_housing.common import print_image_directive
@
<<name='plot_setup', echo=False>>=
seaborn.set_style('whitegrid')
seaborn.color_palette('hls')
@

<<name='data_load', echo=False>>=
housing_features, housing_prices, feature_names = load_housing_data()
housing_data = pandas.DataFrame(housing_features, columns=feature_names)
housing_data['median_value'] = housing_prices
@

The Data
--------

The data was taken from the `sklearn.load_boston <http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html>`_ function, which itself cites the `UCI Machine Learning Repository <http://archive.ics.uci.edu/ml/datasets/Housing>`_ as their source for the data. The data gives values for various features of different suburbs of Boston as well as the median-value for homes in each suburb. The features were chosen to reflect various aspects believed to influence the price of houses including the structure of the house (age and spaciousness), the quality of the neighborhood, transportation access to employment centers and highways, and pollution.

Here is the description of the data variables provided by sklearn.

.. csv-table:: Attribute Information (in order)
   :header: Variable Name, Description
   :delim: :
         
   CRIM     :per capita crime rate by town
   ZN       :proportion of residential land zoned for lots over 25,000 sq.ft.
   INDUS    :proportion of non-retail business acres per town
   CHAS     :Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
   NOX      :nitric oxides concentration (parts per 10 million)
   RM       :average number of rooms per dwelling
   AGE      :proportion of owner-occupied units built prior to 1940
   DIS      :weighted distances to five Boston employment centers
   RAD      :index of accessibility to radial highways
   TAX      :full-value property-tax rate per $10,000
   PTRATIO  :pupil-teacher ratio by town
   B        :1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
   LSTAT    :% lower status of the population
   MEDV     :Median value of owner-occupied homes in $1000's

.. note:: The data comes from the 1970 U.S. Census so its values don't (necessarily) reflect current values.

Cleaning the Data
-----------------

Since there are no missing data points, there isn't much to do to clean the data, but the odd variable names increase the likelihood of error so I'm going to expand them to full variable names.

<<name='renaming', echo=False>>=
new_columns =  ('crime_rate',
                'large_lots',
                'industrial',
                'charles_river',
                'nitric_oxide',
                'rooms',
                'old_houses',
                'distances',
                'highway_access',
                'property_taxes',
                'pupil_teacher_ratio',
                'proportion_blacks',
                'lower_status')
old_names = ('CRIM',
             'ZN',
             'INDUS',
             'CHAS',
             'NOX',
             'RM',
             'AGE',
             'DIS',
             'RAD',
             'TAX',
             'PTRATIO',
             'B',
             'LSTAT')
re_map_names = dict(zip(new_columns, old_names))
@

<<name='re_mapping', echo=False>>=
for new_key, old_key in re_map_names.iteritems():
    housing_data[new_key] = housing_data[old_key]
client_features = pandas.DataFrame(CLIENT_FEATURES, columns=new_columns)
@
<<name='saving_data', echo=False>>=
housing_data.to_hdf('data/housing_data.h5', 'table')
client_features.to_hdf('data/client_features.h5', 'table')
@

.. csv-table:: Variable Aliases
   :header: Original Variable, New Variable
<<name='variable_table', echo=False, wrap=False, results="sphinx">>=
for index, old_name in enumerate(old_names):
    print("   {0},{1}".format(old_name, new_columns[index]))
@

Summary Statistics
------------------

<<name='describe', echo=False, results='sphinx'>>=
description = housing_data.describe()
@
To get a sense of the data I'll look at the shape of the data as well as some summary statistics for the median-value.

.. '

.. csv-table:: Boston Housing Data Shape
   :header: Instances, Features
<<name='data_shape', echo=False, results='sphinx'>>=
print("   {0},{1}".format(len(housing_prices),
                          len(feature_names)))
@

.. csv-table:: Boston Housing median-value statistics (in $1000's)
   :header: Item, Value
<<name='housing_table', echo=False, results='sphinx'>>=
for item in description.index:
    formatter = "   {0},{1:.0f}" if item == 'count' else '   {0},{1:.2f}'
    print(formatter.format(item, description.median_value.loc[item]))
@
.. '

Plots
-----


<<name='distribution', results='sphinx', echo=False, include=False>>=
filename = 'median_value_distribution'
figure = plot.figure()
axe = figure.gca()
grid = seaborn.distplot(housing_data.median_value, ax=axe)
axe.axvline(housing_data.median_value.mean(), label='mean')
axe.axvline(housing_data.median_value.median(), label='median',
            color=seaborn.xkcd_rgb['medium green'])
axe.legend()
title = axe.set_title("Boston Housing Median Values")
print_image_directive(filename, figure, scale='95%')
@

<<name='boxplot', results='sphinx', echo=False, include=False>>=
filename = 'median_value_boxplots'
figure = plot.figure()
axe = figure.gca()
grid = seaborn.boxplot(housing_data.median_value, ax=axe)
title = axe.set_title("Boston Housing Median Values")
print_image_directive(filename, figure, scale='95%')
@


<<name="qqplot", results='sphinx', echo=False, include=False>>=
def qqline_s(ax, x, y, dist, fmt='r-', **plot_kwargs):
    """
    plot qq-line (taken from statsmodels.graphics.qqplot)

    :param:
     - `ax`: matplotlib axes
     - `x`: theoretical_quantiles
     - `y`: sample_quantiles
     - `dist`: scipy.stats distribution
     - `fmt`: format string for line
     - `plot_kwargs`: matplotlib 2Dline keyword arguments
    """
    m, b = y.std(), y.mean()
    reference_line = m * x + b
    ax.plot(x, reference_line, fmt, **plot_kwargs)
    return

filename = 'median_value_qqplot'
figure = plot.figure()
axe = figure.gca()
color_map = plot.get_cmap('Blues')
prob_plot = statsmodels.ProbPlot(housing_data.median_value)
prob_plot.qqplot(ax=axe, color='b', alpha=.25)

qqline_s(ax=axe, dist=prob_plot.dist,
         x=prob_plot.theoretical_quantiles, y=prob_plot.sample_quantiles,
         fmt='-', color=seaborn.xkcd_rgb['medium green'])
         #color=(.33, .66, .27))

title = axe.set_title("Boston Housing Median Values (QQ-Plot)")
print_image_directive(filename, figure)
@ 

<<name='cdf', echo=False, results='sphinx', include=False>>=
filename = 'median_value_cdf'
figure = plot.figure()
axe = figure.gca()
grid = plot.plot(sorted(housing_data.median_value), numpy.linspace(0, 1, housing_data.median_value.count()))
title = axe.set_title("Boston Housing Median Values (CDF)")
axe.set_xlabel("Median Home Value in $1,000's")
print_image_directive(filename, figure)
@

<<name='over_35', echo=False>>=
percentile_90 = housing_data.quantile(.90).median_value
@

Looking at the distribution (histogram and KDE plot) and box-plot the median-values for the homes appear to be right-skewed. The CDF shows that about 90% of the homes are $35,000 or less (the 90th percentile for median-value is 34.8). The qq-plot and the other plots show that the median-values aren't normally distributed.

.. '

<<name='variable_summaries', echo=False, results='sphinx', wrap=False>>=
def summary_table(variables, title='Variables Summaries',
                  number_format="{0:.2f}", data=housing_data):
    """
    Print a csv-table with variable summaries
    :param:
     - `variables`: collection of variables to summarize
     - `title`: Title for the table
     - `number_format`: format string to set decimals
     - `data`: source data to summarize
    """
    statistics = ('min', '25%', '50%', '75%', 'max', 'mean', 'std')
    print(".. csv-table:: {0}".format(title))
    print("   :header: Variable, Min, Q1, Median, Q3, Max, Mean, Std\n")
    for variable in variables:
        description = data[variable].describe()
        stats = ','.join([number_format.format(description.loc[stat])
                          for stat in statistics])
        print("   {0},{1}".format(variable, stats))                                                   
    return
@
Question 1
----------

*Of the features available for each data point, choose three that you feel are significant and give a brief description for each of what they measure.*

To get an idea of how the features are related to the median-value, I'll plot some linear-regressions.

.. '

<<name='regression_plots', echo=False, results='sphinx', include=False>>=
features = re_map_names.keys()
rows = (len(features) // 3)
slice_start = 0

for row in range(1, rows + 1):
    filename = 'housing_data_regression_plots_{0}.png'.format(row)
    grid = seaborn.PairGrid(housing_data, x_vars=features[slice_start:row * 3], y_vars=['median_value'])
    grid.map(seaborn.regplot)
    print_image_directive(filename, grid)
    slice_start = row * 3
@

<<name='last_row', echo=False, include=False, results='sphinx'>>=
if rows % 3:
    print()
    filename = 'figures/housing_data_regression_plots_{0}.png'.format(row + 1)
    grid = seaborn.PairGrid(housing_data, x_vars=features[slice_start:slice_start + rows % 3], y_vars=['median_value'])
    grid.map(seaborn.regplot, ci=95)
    grid.savefig(filename)
    print('.. image:: {0}'.format(filename))
@

Looking at the plots, the three features that I think are the most significant are `lower_status (LSTAT)`, `nitric_oxide (NOX)`, and `rooms (RM)`. The `lower_status` variable is the percent of the population of the town that is of 'lower status' which is defined in this case as being an adult with less than a ninth-grade education or a male worker that is classified as a laborer. The `nitric_oxide` variable represents the annual average parts per million of nitric-oxide measured in the air and is thus a stand-in for pollution. `rooms` is  the average number of rooms per dwelling, representing the spaciousness of houses in the suburb (Harrison, 1978).

Question 2
----------

*Using your client's feature set ``CLIENT_FEATURES``, which values correspond with the features you've chosen above?*

.. csv-table:: Client Features
   :header: Variable, Value
<<name='client_values', echo=False, results='sphinx'>>=
chosen_variables = ('lower_status', 'nitric_oxide', 'rooms')
for variable in chosen_variables:
    print("    {0},{1:.2f}".format(variable, client_features[variable][0]))
@

<<name='variable_summaries', echo=False, results='sphinx', wrap=False>>=
summary_table(chosen_variables)
@

Comparing the values for the client to the median values for the data set as a whole shows that the client has a higher ratio of lower-status adults, more pollution and fewer rooms than the median suburbs so I would expect that the predicted value will be lower than the median.
