<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Evaluating Model Performance &mdash; Predicting Boston Housing Prices 2016.02.21 documentation</title>
    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootswatch-3.3.4/spacelab/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '2016.02.21',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.4/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="Predicting Boston Housing Prices 2016.02.21 documentation" href="index.html" />
    <link rel="next" title="Analyzing Model Performance" href="analyzing_model_performance.html" />
    <link rel="prev" title="Statistical Analysis and Data Exploration" href="statistical_analysis.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          Predicting Boston Housing Prices</a>
        <span class="navbar-text navbar-version pull-left"><b>2016.02.21</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="statistical_analysis.html"> Statistical Analysis and Data Exploration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href=""> Evaluating Model Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="analyzing_model_performance.html"> Analyzing Model Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_prediction.html"> Model Prediction</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Evaluating Model Performance</a><ul>
<li><a class="reference internal" href="#splitting-the-data">Splitting the Data</a></li>
<li><a class="reference internal" href="#choosing-a-performance-metric">Choosing a Performance Metric</a></li>
<li><a class="reference internal" href="#decisiontreeregressor">DecisionTreeRegressor</a></li>
<li><a class="reference internal" href="#grid-search">Grid Search</a><ul>
<li><a class="reference internal" href="#cross-validation">Cross-Validation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="statistical_analysis.html" title="Previous Chapter: Statistical Analysis and Data Exploration"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Statistical A...</span>
    </a>
  </li>
  <li>
    <a href="analyzing_model_performance.html" title="Next Chapter: Analyzing Model Performance"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Analyzing Mod... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/evaluating_model_performance.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="evaluating-model-performance">
<h1>Evaluating Model Performance<a class="headerlink" href="#evaluating-model-performance" title="Permalink to this headline">¶</a></h1>
<p>Here I&#8217;ll discuss splitting the data for training and testing, the performance metric I chose, the algorithm used for the modeling and how the hyper-parameters for the model were chosen.</p>
<div class="section" id="splitting-the-data">
<h2>Splitting the Data<a class="headerlink" href="#splitting-the-data" title="Permalink to this headline">¶</a></h2>
<p>First a function named <cite>shuffle_split_data</cite> was created that acts as an alias for the <cite>train_test_split</cite> function from <cite>sklearn</cite>. The main difference is that the ordering of the data-sets is changed from both x&#8217;s followed by both y&#8217;s to both training sets followed by both testing sets. In this case a 70% training data, 30% test data split was used.</p>
<p>We split the data into training and testing subsets so that we can assess the model using a different data-set than what it
was trained on, thus reducing the likelihood of overfitting the model to the training data and increasing the likelihood that it will generalize to other data.</p>
</div>
<div class="section" id="choosing-a-performance-metric">
<h2>Choosing a Performance Metric<a class="headerlink" href="#choosing-a-performance-metric" title="Permalink to this headline">¶</a></h2>
<p>There are several possible <a class="reference external" href="http://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics">regression metrics</a> to use, but I chose <em>Mean Squared Error</em> as the most appropriate performance metric for predicting housing prices because we are predicting a numeric value (a regression problem) and while <cite>Mean Absolute Error</cite>, <cite>Median Absolute Error</cite>, <cite>Explained Variance Score</cite>, or <cite>r2_score</cite> could also be used, I wanted a metric that would be based on the errors in the model and the MSE emphasizes larger errors more and so I felt it would be preferable.</p>
<p>The <em>Mean Squared Error</em> is an average of the squared differences between predicted values and the actual values.</p>
<div class="math">
<p><img src="_images/math/15d8d8ff6d3e189c2465933ca0972ca04cefbab1.png" alt="MSE(y, \hat{y}) = \frac{1}{n}\sum_{i=0}^{n-1} (y_i - \hat{y}_i)^2"/></p>
</div></div>
<div class="section" id="decisiontreeregressor">
<h2>DecisionTreeRegressor<a class="headerlink" href="#decisiontreeregressor" title="Permalink to this headline">¶</a></h2>
<p>The model was built using sklearn&#8217;s <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html">DecisionTreeRegressor</a>, a non-parametric, tree-based algorithm (using the <a class="reference external" href="http://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart">Classification and Regression Trees (CART)</a> tree algorithm).</p>
</div>
<div class="section" id="grid-search">
<h2>Grid Search<a class="headerlink" href="#grid-search" title="Permalink to this headline">¶</a></h2>
<p>A grid search was used to find the optimal parameters (tree depth) for the DecisionTreeRegressor. The <a class="reference external" href="http://scikit-learn.org/stable/modules/grid_search.html">GridSearchCV</a> algorithm exhaustively works through the parameters it is given to find the parameters that create the best model using cross-validation. Because it is exhaustive it is appropriate when the model-creation is not excessively computationally intensive, otherwise its run-time might be infeasible.</p>
<div class="section" id="cross-validation">
<h3>Cross-Validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">¶</a></h3>
<p>As mentioned, <cite>GridSearchCV</cite> uses <em>cross-validation</em> to find the optimal parameters for a model. Cross-validation is a method of testing a model by partitioning the data into subsets, with each subset taking a turn as the test set while the data not being used as a test-set is used as the training set. This allows the model to be tested against all the data-points, rather than having some data reserved exclusively as training data and the remainder exclusively as testing data.</p>
<p>Because grid-search attempts to find the optimal parameters for a model, it&#8217;s advantageous to use the same training and testing data in each case (case meaning a particular permutation of the parameters) so that the comparisons are equitable. One could simply perform an initial train-validation-test split and use this throughout the grid search, but this then risks the possibility that there was something in the initial split that will bias the outcome. By using all the partitions of the data as both test and training data, as cross-validation does, the chance of a bias in the splitting is reduced and at the same time all the parameter permutations are given the same data to be tested against.</p>
<p>In this case I used <em>k=10</em> for the k-fold cross validation that the <cite>GridSearchCV</cite> uses.</p>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2016, Russell Nakamura.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>